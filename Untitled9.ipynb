{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fda84e94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'v2-ML Model-bangalore_house_price_prediction.ipynb\\n \\nAutomatically generated by Colaboratory.\\n \\nOriginal file is located at\\n    https://colab.research.google.com/drive/1XWPm8WX4DN7ig9rUPXwC1lV2azVn44O2\\n \\n# Bangalore House Price Prediction - Outlier Detection\\n \\nThis notebook only train ML model on different ml algorithms\\n'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"v2-ML Model-bangalore_house_price_prediction.ipynb\n",
    " \n",
    "Automatically generated by Colaboratory.\n",
    " \n",
    "Original file is located at\n",
    "    https://colab.research.google.com/drive/1XWPm8WX4DN7ig9rUPXwC1lV2azVn44O2\n",
    " \n",
    "# Bangalore House Price Prediction - Outlier Detection\n",
    " \n",
    "This notebook only train ML model on different ml algorithms\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "64d09caa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cc664730",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max_columns\", None)\n",
    "pd.set_option(\"display.max_rows\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "efa7b6e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"from google.colab import files\n",
    "files=files.upload()\n",
    "df = pd.read_csv('oh_encoded_data.csv')\"\"\"\n",
    " \n",
    "# Get clean data\n",
    "path = r\"https://drive.google.com/uc?export=download&id=1P49POlAk27uRzWKXoR2WaEfb1lyyfiRJ\" # oh_encoded_data.csv from drive\n",
    " \n",
    "# This file contain [area_type  availability    location    bath    balcony price   total_sqft_int  bhk price_per_sqft]\n",
    "# and ['area_type','availability','location'] this are cat var\n",
    "# We encoded few classes from above car var in OHE "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7280fa6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7120, 109)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(path)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fa26fcbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7120, 108)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape\n",
    " \n",
    "df.head()\n",
    " \n",
    "df = df.drop(['Unnamed: 0'], axis=1)\n",
    "df.head()\n",
    " \n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b08ac3c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X =  (7120, 107)\n",
      "Shape of y =  (7120,)\n",
      "Shape of X_train =  (5696, 107)\n",
      "Shape of y_train =  (5696,)\n",
      "Shape of X_test =  (1424, 107)\n",
      "Shape of y_test =  (1424,)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"## Split Dataset in train and test\"\"\"\n",
    " \n",
    "X = df.drop(\"price\", axis=1)\n",
    "y = df['price']\n",
    "print('Shape of X = ', X.shape)\n",
    "print('Shape of y = ', y.shape)\n",
    " \n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 51)\n",
    "print('Shape of X_train = ', X_train.shape)\n",
    "print('Shape of y_train = ', y_train.shape)\n",
    "print('Shape of X_test = ', X_test.shape)\n",
    "print('Shape of y_test = ', y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8691cfc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"## Feature Scaling\"\"\"\n",
    " \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "sc.fit(X_train)\n",
    "X_train= sc.transform(X_train)\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c1423858",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.790383709268226, 64.89843531105595)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"## Machine Learning Model Training\n",
    " \n",
    "## Linear Regression\n",
    "\"\"\"\n",
    " \n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import mean_squared_error\n",
    "lr = LinearRegression()\n",
    "lr_lasso = Lasso()\n",
    "lr_ridge = Ridge()\n",
    " \n",
    "def rmse(y_test, y_pred):\n",
    "  return np.sqrt(mean_squared_error(y_test, y_pred))\n",
    " \n",
    "lr.fit(X_train, y_train)\n",
    "lr_score = lr.score(X_test, y_test) # with all num var 0.7842744111909903\n",
    "lr_rmse = rmse(y_test, lr.predict(X_test))\n",
    "lr_score, lr_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "687c4ccd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.803637294021051, 62.81324273988928)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lasso \n",
    "lr_lasso.fit(X_train, y_train)\n",
    "lr_lasso_score=lr_lasso.score(X_test, y_test) # with balcony 0.5162364637824872\n",
    "lr_lasso_rmse = rmse(y_test, lr_lasso.predict(X_test))\n",
    "lr_lasso_score, lr_lasso_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9f972e4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.20638035840828173, 126.27806378079055)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"## Support Vector Machine\"\"\"\n",
    " \n",
    "from sklearn.svm import SVR\n",
    "svr = SVR()\n",
    "svr.fit(X_train,y_train)\n",
    "svr_score=svr.score(X_test,y_test) # with 0.2630802200711362\n",
    "svr_rmse = rmse(y_test, svr.predict(X_test))\n",
    "svr_score, svr_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f05303fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8887282551137363, 47.2839946526522)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"## Random Forest Regressor\"\"\"\n",
    " \n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "rfr = RandomForestRegressor()\n",
    "rfr.fit(X_train,y_train)\n",
    "rfr_score=rfr.score(X_test,y_test) # with 0.8863376025408044\n",
    "rfr_rmse = rmse(y_test, rfr.predict(X_test))\n",
    "rfr_score, rfr_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "22789b60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting xgboost\n",
      "  Downloading xgboost-1.5.0-py3-none-win_amd64.whl (106.6 MB)\n",
      "Requirement already satisfied: scipy in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from xgboost) (1.6.2)\n",
      "Note: you may need to restart the kernel to use updated packages.Requirement already satisfied: numpy in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from xgboost) (1.20.1)\n",
      "Installing collected packages: xgboost\n",
      "Successfully installed xgboost-1.5.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2d96f46c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8866071985706575, 47.73252984729787)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"## XGBoost\"\"\"\n",
    " \n",
    "import xgboost \n",
    "xgb_reg = xgboost.XGBRegressor()\n",
    "xgb_reg.fit(X_train,y_train)\n",
    "xgb_reg_score=xgb_reg.score(X_test,y_test) # with 0.8838865742273464\n",
    "xgb_reg_rmse = rmse(y_test, xgb_reg.predict(X_test))\n",
    "xgb_reg_score, xgb_reg_rmse\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f952863e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    Model     Score        RMSE\n",
      "0       Linear Regression  0.790384   64.898435\n",
      "1                   Lasso  0.803637   62.813243\n",
      "2  Support Vector Machine  0.206380  126.278064\n",
      "3           Random Forest  0.888728   47.283995\n",
      "4                 XGBoost  0.886607   47.732530\n"
     ]
    }
   ],
   "source": [
    "print(pd.DataFrame([{'Model': 'Linear Regression','Score':lr_score, \"RMSE\":lr_rmse},\n",
    "              {'Model': 'Lasso','Score':lr_lasso_score, \"RMSE\":lr_lasso_rmse},\n",
    "              {'Model': 'Support Vector Machine','Score':svr_score, \"RMSE\":svr_rmse},\n",
    "              {'Model': 'Random Forest','Score':rfr_score, \"RMSE\":rfr_rmse},\n",
    "              {'Model': 'XGBoost','Score':xgb_reg_score, \"RMSE\":xgb_reg_rmse}],\n",
    "             columns=['Model','Score','RMSE']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "907d2189",
   "metadata": {},
   "source": [
    "Conclusion - Best Model is Random forest because Accuracy score is high and RMSE is low among all algorithm "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
